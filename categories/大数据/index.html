<!DOCTYPE html>

<html lang="zh-CN,en,default">

<head>
  
  <title>分类：大数据 - 最终幻想</title>
  <meta charset="UTF-8">
  <meta name="description" content="一个程序员的心路。">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5">
  
  

  <link rel="shortcut icon" href="/favicon.ico" type="image/png" />
  <meta name="description" content="一个程序员的心路。">
<meta property="og:type" content="website">
<meta property="og:title" content="最终幻想">
<meta property="og:url" content="https://alexguo.net/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/index.html">
<meta property="og:site_name" content="最终幻想">
<meta property="og:description" content="一个程序员的心路。">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Alex Guo">
<meta property="article:tag" content="java web sql linux">
<meta name="twitter:card" content="summary">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/combine/npm/highlight.js@9.15.8/styles/atom-one-dark.css,gh/theme-nexmoe/hexo-theme-nexmoe@latest/source/lib/mdui_043tiny/css/mdui.css,gh/theme-nexmoe/hexo-theme-nexmoe@latest/source/lib/iconfont/iconfont.css,gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css?v=233" crossorigin>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css">
  
  <link rel="stylesheet" href="/css/style.css?v=1619942251119">
<meta name="generator" content="Hexo 5.4.0"></head>

<body class="mdui-drawer-body-left">
  
  <div id="nexmoe-background">
    <div class="nexmoe-bg" style="background-image: url(https://cdn.jsdelivr.net/gh/nexmoe/nexmoe.github.io@latest/images/cover/5c3aec85a4343.jpg)"></div>
    <div class="mdui-appbar mdui-shadow-0">
      <div class="mdui-toolbar">
        <a mdui-drawer="{target: '#drawer', swipe: true}" title="menu" class="mdui-btn mdui-btn-icon mdui-ripple"><i class="mdui-icon nexmoefont icon-menu"></i></a>
        <div class="mdui-toolbar-spacer"></div>
        <!--<a href="javascript:;" class="mdui-btn mdui-btn-icon"><i class="mdui-icon material-icons">search</i></a>-->
        <a href="/" title="Alex Guo" class="mdui-btn mdui-btn-icon"><img src="https://cdn.jsdelivr.net/gh/nexmoe/nexmoe.github.io@latest/images/avatar.png" alt="Alex Guo"></a>
       </div>
    </div>
  </div>
  <div id="nexmoe-header">
      <div class="nexmoe-drawer mdui-drawer" id="drawer">
    <div class="nexmoe-avatar mdui-ripple">
        <a href="/" title="Alex Guo">
            <img src="https://cdn.jsdelivr.net/gh/nexmoe/nexmoe.github.io@latest/images/avatar.png" alt="Alex Guo" alt="Alex Guo">
        </a>
    </div>
    <div class="nexmoe-count">
        <div><span>文章</span>36</div>
        <div><span>标签</span>33</div>
        <div><span>分类</span>10</div>
    </div>
    <div class="nexmoe-list mdui-list" mdui-collapse="{accordion: true}">
        
        <a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/" title="回到首页">
            <i class="mdui-list-item-icon nexmoefont icon-home"></i>
            <div class="mdui-list-item-content">
                回到首页
            </div>
        </a>
        
        <a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/about.html" title="关于博客">
            <i class="mdui-list-item-icon nexmoefont icon-info-circle"></i>
            <div class="mdui-list-item-content">
                关于博客
            </div>
        </a>
        
        <a class="nexmoe-list-item mdui-list-item mdui-ripple" href="/PY.html" title="我的朋友">
            <i class="mdui-list-item-icon nexmoefont icon-unorderedlist"></i>
            <div class="mdui-list-item-content">
                我的朋友
            </div>
        </a>
        
    </div>
    <aside id="nexmoe-sidebar">
  
  <div class="nexmoe-widget-wrap">
    <div class="nexmoe-widget nexmoe-search">
        <form id="search_form" action_e="https://cn.bing.com/search?q=site:nexmoe.com" onsubmit="return search();">
            <label><input id="search_value" name="q" type="search" placeholder="搜索"></label>
        </form>
    </div>
</div>
  
  <div class="nexmoe-widget-wrap">
    <div class="nexmoe-widget nexmoe-social">
        <a class="mdui-ripple" href="https://jq.qq.com/?_wv=1027&k=5CfKHun" target="_blank" mdui-tooltip="{content: 'QQ群'}" style="color: rgb(249, 174, 8);background-color: rgba(249, 174, 8, .1);">
            <i class="nexmoefont icon-QQ"></i>
        </a><a class="mdui-ripple" href="https://space.bilibili.com/20238211" target="_blank" mdui-tooltip="{content: '哔哩哔哩'}" style="color: rgb(231, 106, 141);background-color: rgba(231, 106, 141, .15);">
            <i class="nexmoefont icon-bilibili"></i>
        </a><a class="mdui-ripple" href="https://github.com/nexmoe/" target="_blank" mdui-tooltip="{content: 'GitHub'}" style="color: rgb(25, 23, 23);background-color: rgba(25, 23, 23, .15);">
            <i class="nexmoefont icon-github"></i>
        </a>
    </div>
</div>
  
  
  <div class="nexmoe-widget-wrap">
    <h3 class="nexmoe-widget-title">文章分类</h3>
    <div class="nexmoe-widget">

      <ul class="category-list">

        


        

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/android/">android</a>
          <span class="category-list-count">1</span>
        </li>

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/java/">java</a>
          <span class="category-list-count">11</span>
        </li>

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/linux/">linux</a>
          <span class="category-list-count">1</span>
        </li>

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/no-sql/">no sql</a>
          <span class="category-list-count">1</span>
        </li>

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/spring/">spring</a>
          <span class="category-list-count">1</span>
        </li>

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/大数据/">大数据</a>
          <span class="category-list-count">9</span>
        </li>

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/家常/">家常</a>
          <span class="category-list-count">2</span>
        </li>

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/常用工具/">常用工具</a>
          <span class="category-list-count">5</span>
        </li>

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/数据库/">数据库</a>
          <span class="category-list-count">2</span>
        </li>

        

        <li class="category-list-item">
          <a class="category-list-link" href="/categories/网络/">网络</a>
          <span class="category-list-count">1</span>
        </li>

        
      </ul>

    </div>
  </div>


  
  
  <div class="nexmoe-widget-wrap">
    <div id="randomtagcloud" class="nexmoe-widget tagcloud nexmoe-rainbow">
      <a href="/tags/EventBus/" style="font-size: 10px;">EventBus</a> <a href="/tags/NIO/" style="font-size: 10px;">NIO</a> <a href="/tags/bin-log/" style="font-size: 13.33px;">bin_log</a> <a href="/tags/docker/" style="font-size: 13.33px;">docker</a> <a href="/tags/elasticsearch/" style="font-size: 10px;">elasticsearch</a> <a href="/tags/filebeat/" style="font-size: 10px;">filebeat</a> <a href="/tags/flume/" style="font-size: 10px;">flume</a> <a href="/tags/framework/" style="font-size: 10px;">framework</a> <a href="/tags/git/" style="font-size: 13.33px;">git</a> <a href="/tags/gitlab/" style="font-size: 10px;">gitlab</a> <a href="/tags/hbase/" style="font-size: 10px;">hbase</a> <a href="/tags/hdfs/" style="font-size: 10px;">hdfs</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/tags/http/" style="font-size: 10px;">http</a> <a href="/tags/java%E5%9F%BA%E7%A1%80/" style="font-size: 10px;">java基础</a> <a href="/tags/jvm/" style="font-size: 13.33px;">jvm</a> <a href="/tags/kafka/" style="font-size: 10px;">kafka</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/logstash/" style="font-size: 10px;">logstash</a> <a href="/tags/logstash-forward/" style="font-size: 10px;">logstash-forward</a> <a href="/tags/mongodb/" style="font-size: 10px;">mongodb</a> <a href="/tags/mysql/" style="font-size: 16.67px;">mysql</a> <a href="/tags/netty/" style="font-size: 10px;">netty</a> <a href="/tags/pcloud/" style="font-size: 20px;">pcloud</a> <a href="/tags/rocketMQ/" style="font-size: 10px;">rocketMQ</a> <a href="/tags/spark/" style="font-size: 10px;">spark</a> <a href="/tags/spring/" style="font-size: 13.33px;">spring</a> <a href="/tags/spring-cloud/" style="font-size: 10px;">spring cloud</a> <a href="/tags/spring-cloud-stream/" style="font-size: 10px;">spring cloud stream</a> <a href="/tags/spring-rabbitMQ/" style="font-size: 10px;">spring rabbitMQ</a> <a href="/tags/%E5%85%B6%E4%BB%96/" style="font-size: 13.33px;">其他</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/" style="font-size: 10px;">数据采集</a> <a href="/tags/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/" style="font-size: 10px;">日志分析</a>
    </div>
    
  </div>

  
</aside>
    <div class="nexmoe-copyright">
        &copy; 2021 Alex Guo
        Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
        & <a href="https://github.com/theme-nexmoe/hexo-theme-nexmoe" target="_blank">Nexmoe</a>
        
    </div>
</div><!-- .nexmoe-drawer -->
  </div>
  <div id="nexmoe-content">
    <div class="nexmoe-primary">
        <section class="nexmoe-posts">
    
    <div class="nexmoe-post">
        <a href="/2018/12/28/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E6%96%B9%E6%B3%95/">
            
                <div class="nexmoe-post-cover mdui-ripple" style="padding-bottom: 66.66666666666666%;"> 
                    <img data-src="https://cdn.jsdelivr.net/gh/nexmoe/nexmoe.github.io@latest/images/cover/5c3aec85a4343.jpg" data-sizes="auto" alt="大数据之数据采集方法" class="lazyload">
                    <h1>大数据之数据采集方法</h1>
                </div>
            
        </a>

        <div class="nexmoe-post-meta nexmoe-rainbow-fill">
            <a><i class="nexmoefont icon-calendar-fill"></i>2018年12月28日</a>
            <a><i class="nexmoefont icon-areachart"></i>629 字</a>
            <a><i class="nexmoefont icon-time-circle-fill"></i>大概 2 分钟</a>
        </div>

        <article>
            
                <h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>数据源的分类，大体可以分为三类：结构化数据，半结构化数据，非结构化数据</p>
<p>首先，我们面临的数据源多而杂，有来自公司自有平台的数据，来自第三方现有的数据，来自通过爬取获取的数据。</p>
<h1 id="自有平台数据的采集"><a href="#自有平台数据的采集" class="headerlink" title="自有平台数据的采集"></a>自有平台数据的采集</h1><p>自有平台的数据包括：自有系统中的数据和各个部门手动整理的历史数据<br>（1）自有系统的数据，存放在oracle数据库中，而我们抽取的数据统一放在一个数据平台，数据平台采用的数据库为mongodb。所以自有系统的数据采集，关键是如何从oracle到mongodb中。</p>
<h2 id="如果采集的数据对实时性要求比较高，那么采用ogg实时迁移方案。"><a href="#如果采集的数据对实时性要求比较高，那么采用ogg实时迁移方案。" class="headerlink" title="如果采集的数据对实时性要求比较高，那么采用ogg实时迁移方案。"></a>如果采集的数据对实时性要求比较高，那么采用ogg实时迁移方案。</h2><p>oracle to oracle迁移方案<br>oracle to mongodb迁移方案</p>
<h2 id="如果采集数据对实时性要求不高，那么采用定时的迁移方案：使用etl工具进行数据迁移（spoon）"><a href="#如果采集数据对实时性要求不高，那么采用定时的迁移方案：使用etl工具进行数据迁移（spoon）" class="headerlink" title="如果采集数据对实时性要求不高，那么采用定时的迁移方案：使用etl工具进行数据迁移（spoon）"></a>如果采集数据对实时性要求不高，那么采用定时的迁移方案：使用etl工具进行数据迁移（spoon）</h2><p>（2）自有数据，还有一部分是以csv或txt的形式存在</p>
<h2 id="如果对实时性要求比较高：使用flume对日志进行收集，然后存放的mongodb中"><a href="#如果对实时性要求比较高：使用flume对日志进行收集，然后存放的mongodb中" class="headerlink" title="如果对实时性要求比较高：使用flume对日志进行收集，然后存放的mongodb中"></a>如果对实时性要求比较高：使用flume对日志进行收集，然后存放的mongodb中</h2><h2 id="如果对实时性要求不高：使用mongodbimport工具导入mongodb即可"><a href="#如果对实时性要求不高：使用mongodbimport工具导入mongodb即可" class="headerlink" title="如果对实时性要求不高：使用mongodbimport工具导入mongodb即可"></a>如果对实时性要求不高：使用mongodbimport工具导入mongodb即可</h2><h1 id="第三方现有数据的采集半结构化数据"><a href="#第三方现有数据的采集半结构化数据" class="headerlink" title="第三方现有数据的采集半结构化数据"></a>第三方现有数据的采集半结构化数据</h1><p>仅有自有的数据是不足以支撑业务需求的分析，所以收集第三方数据是必须的，第三方的数据来源就多种多样了，大体可以二类：来自数据库中的半结构化数据，来自文件的半结构化数据</p>
<h2 id="如果数据来自关系型数据库mysql或oracle，并且提供的是dmp文件，那么就需要将获取的数据存入到mongodb。这里提供两种思路："><a href="#如果数据来自关系型数据库mysql或oracle，并且提供的是dmp文件，那么就需要将获取的数据存入到mongodb。这里提供两种思路：" class="headerlink" title="如果数据来自关系型数据库mysql或oracle，并且提供的是dmp文件，那么就需要将获取的数据存入到mongodb。这里提供两种思路："></a>如果数据来自关系型数据库mysql或oracle，并且提供的是dmp文件，那么就需要将获取的数据存入到mongodb。这里提供两种思路：</h2><p>（1）先将数据存入oracle或mysql，然后使用上述迁移方案完成数据的采集<br>（2）直接将获取的数据，使用工具导入到oracle<br>如果数据提供的是txt或csv文件，那么直接使用mongoimport导入mongodb</p>
<h2 id="非结构化数据采集"><a href="#非结构化数据采集" class="headerlink" title="非结构化数据采集"></a>非结构化数据采集</h2><p>这一节，没多少要讲的。因为没有接触很深，但是后续是个必须的过程。使用python爬取各种数据，存储成csv或txt文件<br>爬取的文件，再使用mongodbimport导入mongodb中</p>
<p>由于要提供数据的可视化和搜索平台，建议使用ELK的技术栈，所以数据的收集使用Logstash
　</p>

            
        </article>
    </div>
    
    <div class="nexmoe-post">
        <a href="/2018/12/19/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86%E6%96%B9%E6%A1%88%EF%BC%9Amysql-binlog-%E6%B3%A8%E6%84%8F%E7%82%B9/">
            
                <div class="nexmoe-post-cover mdui-ripple" style="padding-bottom: 66.66666666666666%;"> 
                    <img data-src="https://cdn.jsdelivr.net/gh/nexmoe/nexmoe.github.io@latest/images/cover/5c3aec85a4343.jpg" data-sizes="auto" alt="大数据采集方案：mysql-binlog 注意点" class="lazyload">
                    <h1>大数据采集方案：mysql-binlog 注意点</h1>
                </div>
            
        </a>

        <div class="nexmoe-post-meta nexmoe-rainbow-fill">
            <a><i class="nexmoefont icon-calendar-fill"></i>2018年12月19日</a>
            <a><i class="nexmoefont icon-areachart"></i>489 字</a>
            <a><i class="nexmoefont icon-time-circle-fill"></i>大概 2 分钟</a>
        </div>

        <article>
            
                <h1 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h1><p>在大数据时代，数据研发人员总是想把各类数据采集到我们的数据仓库。最典型的方案是日志收集方案： flume采集文件，转发到kafka，再使用storm写到hdfs。但是实际场景中，我们的数据源不止文件，还有mysql这类db数据。</p>
<p>众所周知，mysql是可以开启binlog的，也就是说我们对db的每个操作都可以通过binlog解析得到。所以我们实时解析mysql的binlog文件，即可实时获取到db的各个变更事件，就可以实时地将insert的数据，像tail日志文件一样，以规范化的形式发送到我们后端的消息中间件。</p>
<p>本文不会拘泥于实现细节，只会列举几个注意点，避免后续人采坑。</p>
<h1 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h1><p>binlog row模式<br>最需要支持的点：<br>mysql必须支持binlog，且必须是row模式。需要关注几个问题：<br>1.row模式的binlog是远大于其他模式，需要注意磁盘容量<br>2.从其他模式binlog（如mix）改为row模式，需要断开已有mysql的连接，需要dba及相关业务开发评估可行性。<br>3.不需要采集的库表要独立出去，不然大量无关binlog会影响采集器的性能，堵塞通道。（需要推动业务改）<br>4.row模式下日志变多，还有从库解析方式发生变化，可能会造成主从不一致（状态延迟）的情况，需要dba确认</p>
<h1 id="支持的语句"><a href="#支持的语句" class="headerlink" title="支持的语句"></a>支持的语句</h1><p>不支持DDL，只是inset最好，就类似文件的append。update、delete都会增加后端的处理逻辑。</p>
<h1 id="事务支持"><a href="#事务支持" class="headerlink" title="事务支持"></a>事务支持</h1><p>本身就是用于大数据处理的，不支持事务</p>
<h1 id="字段问题"><a href="#字段问题" class="headerlink" title="字段问题"></a>字段问题</h1><p>建议末尾追加字段，只用简易字段（int，string）</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>binlog方案技术上没什么特别难点，重点还是运营的坑比较多
 </p>

            
        </article>
    </div>
    
    <div class="nexmoe-post">
        <a href="/2018/12/18/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F-hdfs%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8/">
            
                <div class="nexmoe-post-cover mdui-ripple" style="padding-bottom: 66.66666666666666%;"> 
                    <img data-src="https://cdn.jsdelivr.net/gh/nexmoe/nexmoe.github.io@latest/images/cover/5c3aec85a4343.jpg" data-sizes="auto" alt="大数据日志分析系统-hdfs日志存储" class="lazyload">
                    <h1>大数据日志分析系统-hdfs日志存储</h1>
                </div>
            
        </a>

        <div class="nexmoe-post-meta nexmoe-rainbow-fill">
            <a><i class="nexmoefont icon-calendar-fill"></i>2018年12月18日</a>
            <a><i class="nexmoefont icon-areachart"></i>790 字</a>
            <a><i class="nexmoefont icon-time-circle-fill"></i>大概 3 分钟</a>
        </div>

        <article>
            
                <h1 id="hdfs简介："><a href="#hdfs简介：" class="headerlink" title="hdfs简介："></a>hdfs简介：</h1><p>Hadoop分布式文件系统(HDFS)被设计成适合运行在通用硬件(commodity hardware)上的分布式文件系统。</p>
<h1 id="项目需求："><a href="#项目需求：" class="headerlink" title="项目需求："></a>项目需求：</h1><p>使用hdfs存储客户需要的指定域名时间打包日志 以及原始日志存储进行离线计算</p>
<h1 id="遇到的问题："><a href="#遇到的问题：" class="headerlink" title="遇到的问题："></a>遇到的问题：</h1><p>在这一步遇到的一个重要的问题：</p>
<p>问题：从kafka中日志直接按域名时间分类存入hdfs时速度不够,主要时数据量太大，当数据量减少到1/10的时候满足要求。</p>
<h1 id="试过："><a href="#试过：" class="headerlink" title="试过："></a>试过：</h1><ul>
<li><p>spark：从kafka取出数据日志解析存入hdfs</p>
</li>
<li><p>logstash: 从kfaka中取出数据，然后自定义conf配置文件，按域名按小时直接存入hdfs</p>
</li>
<li><p>flume： flume自定义filter插件（java写的），将原始日志按照时间域名分类存入hdfs</p>
</li>
</ul>
<p>发现这些东西都是存入hdfs速度不够，当然同时也看hdfs日志，hdfs本来就是适合大文件存储，同时每条日志存储有自己的路径有namenode datanode，现在这样一条日志或者百千条日志就进行一次日志存储的效率明显很低。</p>
<h1 id="进行速度测试："><a href="#进行速度测试：" class="headerlink" title="进行速度测试："></a>进行速度测试：</h1><ul>
<li><p>spark - kafka -logstash:从spark从kafka中取出原始日志然后将结果写入kafka的另一个topic这样的速度是OK的， 然后尝试结果数据再次通过logstash从kafka取出写入hdfs速度是跟不上的。</p>
</li>
<li><p>flume： 直接从kafka中取出然后按域名时间分类，写入本地或者直接屏幕上打印速度都是可以的。</p>
</li>
</ul>
<h1 id="最后的解决是："><a href="#最后的解决是：" class="headerlink" title="最后的解决是："></a>最后的解决是：</h1><p>flume自定义fliter插件（java），outPutSink插件（java），写入本地（这样已经测试速度是OK的，时间域名分割存储还未OK），本地形成大文件后写入hdfs（这里可以直接通过hdfs的api实现，linux定时脚本调用即可）</p>
<h1 id="当然也可以直接用hbase进行原始日志的存储"><a href="#当然也可以直接用hbase进行原始日志的存储" class="headerlink" title="当然也可以直接用hbase进行原始日志的存储"></a>当然也可以直接用hbase进行原始日志的存储</h1><p>git地址示例：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/penghaoyou5/Flume-plug-in-log">https://github.com/penghaoyou5/Flume-plug-in-log</a></p>
<p>直接上配置：</p>
<pre><code>ubuntu@sp26:~/apps/hadoop-2.6.4/etc/hadoop$ cat core-site.xml
&lt;configuration&gt;
&lt;property&gt;
&lt;name&gt;fs.defaultFS&lt;/name&gt;
&lt;value&gt;hdfs://sp26:9000&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
&lt;value&gt;/home/ubuntu/hdpdata&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<pre><code>ubuntu@sp26:~/apps/hadoop-2.6.4/etc/hadoop$ cat hadoop-env.sh
export JAVA_HOME=/home/ubuntu/apps/jdk1.7.0_45
</code></pre>
<pre><code>ubuntu@sp26:~/apps/hadoop-2.6.4/etc/hadoop$ cat hdfs-site.xml
&lt;configuration&gt;
&lt;property&gt;
&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
&lt;value&gt;/mnt/data2/wlkhadname,/mnt/data3/wlkhadname,/mnt/data4/wlkhadname,/mnt/data5/wlkhadname,/mnt/data6/wlkhadname,/mnt/data7/wlkhadname,/mnt/data8/wlkhadname,/mnt/data9/wlkhadname,/mnt/data10/wlkhadname&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
&lt;value&gt;/mnt/data2/wlkhaddata,/mnt/data3/wlkhaddata,/mnt/data4/wlkhaddata,/mnt/data5/wlkhaddata,/mnt/data6/wlkhaddata,/mnt/data7/wlkhaddata,/mnt/data8/wlkhaddata,/mnt/data9/wlkhaddata,/mnt/data10/wlkhaddata&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;dfs.replication&lt;/name&gt;
&lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;dfs.secondary.http.address&lt;/name&gt;
&lt;value&gt;sp26:50090&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
        &lt;name&gt;dfs.datanode.max.xcievers&lt;/name&gt;
        &lt;value&gt;8192&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<p><code>ubuntu@sp26:~/apps/hadoop-2.6.4/etc/hadoop$ cat slaves  sp27 sp28 sp29 sp30</code>　</p>

            
        </article>
    </div>
    
    <div class="nexmoe-post">
        <a href="/2018/12/18/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F-spark%E8%BF%9B%E8%A1%8C%E6%97%A5%E5%BF%97%E8%AE%A1%E7%AE%97/">
            
                <div class="nexmoe-post-cover mdui-ripple" style="padding-bottom: 66.66666666666666%;"> 
                    <img data-src="https://cdn.jsdelivr.net/gh/nexmoe/nexmoe.github.io@latest/images/cover/5c3aec85a4343.jpg" data-sizes="auto" alt="大数据日志分析系统-spark进行日志计算" class="lazyload">
                    <h1>大数据日志分析系统-spark进行日志计算</h1>
                </div>
            
        </a>

        <div class="nexmoe-post-meta nexmoe-rainbow-fill">
            <a><i class="nexmoefont icon-calendar-fill"></i>2018年12月18日</a>
            <a><i class="nexmoefont icon-areachart"></i>530 字</a>
            <a><i class="nexmoefont icon-time-circle-fill"></i>大概 2 分钟</a>
        </div>

        <article>
            
                <p>#spark简介：<br>Apache Spark 是专为大规模数据处理而设计的快速通用的计算引擎。</p>
<p>#需要满足的项目需求：<br>用spark进行实时统计，从kafka中获取数据，流式计算每分钟一次将计算结果存入es，供客户进行查询。</p>
<p>#这里不用直接存入es的方式进行聚合或者存入es之后再进行计算的原因：</p>
<ul>
<li><p>1.直接存入es进行聚合的话es中会随着时间的推移保存大量的原始日志，es存入数据量太大的数据会产生性能问题,而且大量用户同时查询也会产生聚合过多的性能问题。</p>
</li>
<li><p>2.先将原始日志存入es，计算结果数据后再次删除原始日志   会产生问题： </p>
</li>
</ul>
<p>    - 1）虽然现有数据量es能够满足要求，但是当数据量再次大增时会产生kafka堆积 - es速度跟不上，而spark的处理速度可以跟得上  </p>
<p>    - 2）实时性在逻辑上和技术上得不到很好的保证。例如每次计算当前时间前5分钟的日志（线上python脚本运行时计算当前时间前1小时日志），一旦数据量过大产生kafka堆积，日志不能实时收集到es就会产生计算数据少的问题。</p>
<p>#做的过程中遇到的问题：<br>遇到过内存问题，算是由于缓存处理不当引起的 后来改用了LruCache      现象是不断的进行消费没有产生kafka堆积，但是没有结果数据，运行正常</p>
<p>#spark配置：</p>
<pre><code>ubuntu@sp26:~/apps/spark-1.6.1-bin-hadoop2.6/conf$ cat spark-env.sh | grep -v &#39;#&#39;
export JAVA_HOME=/home/ubuntu/apps/jdk1.8.0_144

export SPARK_MASTER_IP=sp26

export SPARK_MASTER_PORT=7077
</code></pre>
<pre><code>ubuntu@sp26:~/apps/spark-1.6.1-bin-hadoop2.6/conf$ cat slaves

sp27

sp28

sp29

sp30
</code></pre>
<p>#当然要有 ssh免密配置，linux环境变量配置等等，以后的文章会进行补充</p>
<pre><code>启动ubuntu@sp26:~/apps/spark-1.6.1-bin-hadoop2.6$ sbin/start-all.sh

http://sp26:8080

这先是单节点
</code></pre>
<p>#spark代码：<br>git地址：<a target="_blank" rel="noopener" href="https://github.com/penghaoyou5/SparkLogAnalysis.git">https://github.com/penghaoyou5/SparkLogAnalysis.git</a></p>

            
        </article>
    </div>
    
    <div class="nexmoe-post">
        <a href="/2018/12/18/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F-elasticsearch/">
            
                <div class="nexmoe-post-cover mdui-ripple" style="padding-bottom: 66.66666666666666%;"> 
                    <img data-src="https://cdn.jsdelivr.net/gh/nexmoe/nexmoe.github.io@latest/images/cover/5c3aec85a4343.jpg" data-sizes="auto" alt="大数据日志分析系统-elasticsearch" class="lazyload">
                    <h1>大数据日志分析系统-elasticsearch</h1>
                </div>
            
        </a>

        <div class="nexmoe-post-meta nexmoe-rainbow-fill">
            <a><i class="nexmoefont icon-calendar-fill"></i>2018年12月18日</a>
            <a><i class="nexmoefont icon-areachart"></i>748 字</a>
            <a><i class="nexmoefont icon-time-circle-fill"></i>大概 4 分钟</a>
        </div>

        <article>
            
                <h1 id="elasticsearch简介"><a href="#elasticsearch简介" class="headerlink" title="elasticsearch简介"></a>elasticsearch简介</h1><p>Elasticsearch 是一个分布式、可扩展、实时的搜索与数据分析引擎。</p>
<h1 id="两种架构的es配置差不多"><a href="#两种架构的es配置差不多" class="headerlink" title="两种架构的es配置差不多"></a>两种架构的es配置差不多</h1><h1 id="选用es存储结果数据的理由："><a href="#选用es存储结果数据的理由：" class="headerlink" title="选用es存储结果数据的理由："></a>选用es存储结果数据的理由：</h1><p>1.曾经考虑过hbase选用，也进行过真正的测试，用hbse的问题是这种键值对的数据库，不一定能够保证唯一的键（虽然能把时间戳加入key中），而且es本身只存储结果数据完全符合线上需求，并且es自身带有聚合功能，可以多个条件查询而不只是键值对。</p>
<h1 id="es原先配置："><a href="#es原先配置：" class="headerlink" title="es原先配置："></a>es原先配置：</h1><p>es总共11个节点  进行了角色分配  其中master节点3个  data节点5个  cient节点3个 (角色分配与 node.master    node.data 有关)</p>
<pre><code>ubuntu@sp1:~/elasticsearch-5.5.2/config$ cat elasticsearch.yml | grep -v &#39;#&#39;

 cluster.name: webluker-logstash

 cluster.routing.allocation.balance.shard: 0.10 

 node.name: node-c-sp1

 node.master: false

 node.data: false

 path.data: /mnt/data2,/mnt/data3,/mnt/data4,/mnt/data5,/mnt/data6,/mnt/data7,/mnt/data8,/mnt/data9,/mnt/data10

 network.host: 0.0.0.0

 discovery.zen.ping.unicast.hosts: [&quot;master-ip1&quot;,&quot;master-ip2&quot;,&quot;master-ip3&quot;]

 discovery.zen.minimum_master_nodes: 2

 discovery.zen.ping_timeout: 100s

 discovery.zen.fd.ping_timeout: 100s

 discovery.zen.fd.ping_interval: 30s

 gateway.expected_nodes: 8

 gateway.recover_after_nodes: 5

 thread_pool.bulk.queue_size: 2000

 thread_pool.search.queue_size: 3000
</code></pre>
<pre><code>ubuntu@sp34:~/elasticsearch-5.5.2/bin$ cat elasticsearch | grep -v &#39;#&#39;

JAVA_HOME=&quot;/home/ubuntu/jdk1.8.0_144&quot;

ES_JAVA_OPTS=&quot;-Xms31g -Xmx31g&quot;
</code></pre>
<p>//==================</p>
<h1 id="es-spark计算配置"><a href="#es-spark计算配置" class="headerlink" title="es spark计算配置"></a>es spark计算配置</h1><pre><code>ubuntu@sp26:~/apps/elasticsearch-5.5.2/bin$ cat elasticsearch | grep -v &#39;#&#39;

JAVA_HOME=&quot;/home/ubuntu/apps/jdk1.8.0_144&quot;

ES_JAVA_OPTS=&quot;-Xms31g -Xmx31g&quot;

ES_HOME=/home/ubuntu/apps/elasticsearch-5.5.2
</code></pre>
<pre><code>ubuntu@sp26:~/apps/elasticsearch-5.5.2/config$ cat elasticsearch.yml | grep -v &#39;#&#39;

cluster.name: log_big_data_wlk

discovery.zen.ping.unicast.hosts: [&quot;es-master-ip1&quot;,&quot;es-master-ip2&quot;,&quot;es-master-ip3&quot;]

discovery.zen.minimum_master_nodes: 2

node.name: node-m-d-sp26

path.data: /mnt/data2,/mnt/data3,/mnt/data4,/mnt/data5,/mnt/data6,/mnt/data7,/mnt/data8,/mnt/data9,/mnt/data10,/mnt/data11

network.host: 0.0.0.0

http.cors.enabled: true

http.cors.allow-origin: &quot;*&quot;
</code></pre>
<p>//================================</p>
<h2 id="当然还有es-header插件安装："><a href="#当然还有es-header插件安装：" class="headerlink" title="当然还有es header插件安装："></a>当然还有es header插件安装：</h2><h1 id="kibana安装："><a href="#kibana安装：" class="headerlink" title="kibana安装："></a>kibana安装：</h1><p>//======</p>
<h1 id="es问题"><a href="#es问题" class="headerlink" title="es问题"></a>es问题</h1><p>1.es索引过多问题    linux定时脚本删除</p>
<p>2.es索引创建异常，同一时间创建太多 ，那就是前边计算上传有问题了</p>
<p>3.es的shell监控脚本 （这里是配合zabbix使用发送邮件）</p>
<pre><code>#!/usr/bin/env bash
#字符串截取参考 https://www.cnblogs.com/zwgblog/p/6031256.html
#判断字符串包含参考 https://www.cnblogs.com/AndyStudy/p/6064834.html
es_url=&#39;http://sp26:9200&#39;
var=&#39;0&#39;

#======判断集群健康值是否是green
health_result=`curl -s $es_url/_cluster/health`
#echo ddd$health_result
if [[ $health_result == *&#39;&quot;status&quot;:&quot;green&quot;&#39;* ]]
then
#     echo &quot;包含&quot;
     pass=&#39;yes&#39;
else
     echo &quot;不包含green&quot;
fi
#====获取上个小时的日志数量 参考是否达标
last_hour=`date +%Y.%m.%d.%H  -d  &#39;-1 hours&#39;`
#last_hour=&#39;2017.12.13.13&#39;
last_hour_index=&#39;logstash-&#39;$last_hour
result_query=`curl -s $&#123;es_url&#125;/$&#123;last_hour_index&#125;/_search -d &#39;&#123;&quot;query&quot;:&#123;&quot;bool&quot;:&#123;&quot;must&quot;:[&#123;&quot;match_all&quot;:&#123;&#125;&#125;]&#125;&#125;,&quot;size&quot;:0&#125;&#39;`
#echo $result_query
right_total=$&#123;result_query#*&#39;&quot;hits&quot;:&#123;&quot;total&quot;:&#39;&#125;
hits_total=$&#123;right_total%&#39;,&quot;max_score&quot;&#39;*&#125;
#echo $hits_total
if [ $hits_total  -lt 1000000 ]
then
    echo &#39;数据量&lt;1000000&#39;
fi
echo $var
</code></pre>

            
        </article>
    </div>
    
    <div class="nexmoe-post">
        <a href="/2018/12/18/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F-logstash/">
            
                <div class="nexmoe-post-cover mdui-ripple" style="padding-bottom: 66.66666666666666%;"> 
                    <img data-src="https://cdn.jsdelivr.net/gh/nexmoe/nexmoe.github.io@latest/images/cover/5c3aec85a4343.jpg" data-sizes="auto" alt="大数据日志分析系统-logstash" class="lazyload">
                    <h1>大数据日志分析系统-logstash</h1>
                </div>
            
        </a>

        <div class="nexmoe-post-meta nexmoe-rainbow-fill">
            <a><i class="nexmoefont icon-calendar-fill"></i>2018年12月18日</a>
            <a><i class="nexmoefont icon-areachart"></i>1.1k 字</a>
            <a><i class="nexmoefont icon-time-circle-fill"></i>大概 6 分钟</a>
        </div>

        <article>
            
                <h1 id="logstash简介"><a href="#logstash简介" class="headerlink" title="logstash简介"></a>logstash简介</h1><p>Logstash 是一个开源的数据收集引擎，它具有备实时数据传输能力。它可以统一过滤来自不同源的数据，并按照开发者的制定的规范输出到目的地。</p>
<h1 id="logstash-2-2-2的配置："><a href="#logstash-2-2-2的配置：" class="headerlink" title="logstash-2.2.2的配置："></a>logstash-2.2.2的配置：</h1><h2 id="从logstash-forward-到kafka的配置"><a href="#从logstash-forward-到kafka的配置" class="headerlink" title="从logstash-forward 到kafka的配置"></a>从logstash-forward 到kafka的配置</h2><pre><code>ubuntu@sp1:~/logstashBeforeChangeConf$ cat /home/ubuntu/logstash-2.2.2/config/before-kafka-access.conf


input &#123;
      lumberjack &#123;
                    port =&gt; &quot;5044&quot;
                    ssl_certificate =&gt; &quot;/home/ubuntu/logstash-2.2.2/config/lumberjack.crt&quot;
                    ssl_key =&gt;  &quot;/home/ubuntu/logstash-2.2.2/config/lumberjack.key&quot;
                    type =&gt; &quot;fc_access&quot;
                  &#125;
      &#125;

output &#123;
       if &quot;_grokparsefailure&quot; not in [tags] &#123;
    #       stdout &#123; codec =&gt; rubydebug &#125;
       kafka &#123;
                topic_id =&gt; &quot;kafka_es&quot;
                bootstrap_servers =&gt; &quot;sp1:9092,sp2:9092,sp3:9092,sp4:9092,sp5:9092,sp6:9092,sp7:9092&quot;
                compression_type =&gt; &quot;snappy&quot; 
                acks =&gt; [&quot;1&quot;]
                value_serializer =&gt; &quot;org.apache.kafka.common.serialization.StringSerializer&quot;
                timeout_ms =&gt; 10000
                retries =&gt; 5
                retry_backoff_ms =&gt; 100
                send_buffer_bytes =&gt; 102400   
                workers =&gt; 2
             &#125;
      &#125;
&#125;
</code></pre>
<h2 id="从kafka到es配置"><a href="#从kafka到es配置" class="headerlink" title="从kafka到es配置"></a>从kafka到es配置</h2><p>其中包括了对日志各个字段的解析,以及对异常日志过滤（同时注意其中过滤了 不属于当前时间前后5天的时间的日志，为了防止异常日志创建索引过多导致es报红）</p>
<pre><code>ubuntu@sp1:~/logstashAfterChangeConf$ cat /home/ubuntu/logstash-2.2.2/config/after-kafa-access.conf

input &#123;
      kafka &#123;
        topic_id =&gt; &quot;kafka_es&quot;
        group_id =&gt; &quot;kafka_es&quot;
        zk_connect =&gt; &quot;sp1:2181,sp2:2181,sp3:2181,sp4:2181,sp5:2181,sp6:2181,sp7:2181&quot; 
        consumer_threads =&gt; 1
        consumer_restart_on_error =&gt; true
        consumer_restart_sleep_ms =&gt; 5000
        decorate_events =&gt; true
        consumer_timeout_ms =&gt; 1000
        queue_size =&gt; 100
        auto_offset_reset =&gt; &quot;smallest&quot;
        rebalance_max_retries =&gt; 50
      &#125;
&#125;

filter &#123;
       mutate &#123;
             add_field =&gt; [ &quot;messageClone&quot;, &quot;%&#123;message&#125;&quot; ]
       &#125;

       mutate &#123;
             split =&gt; &#123; &quot;messageClone&quot; =&gt; &#39;&quot;&#39; &#125;
            add_field =&gt; &#123;&quot;agent&quot; =&gt; &quot;%&#123;[messageClone][3]&#125;&quot;&#125;

       &#125;
       useragent &#123; 
              source =&gt; &quot;agent&quot; 
       &#125;

       mutate &#123;
            split =&gt; &#123; &quot;message&quot; =&gt; &quot; &quot; &#125;
            add_field =&gt; &#123;&quot;timestamp&quot; =&gt; &quot;%&#123;[message][0]&#125;&quot;&#125;
            add_field =&gt; &#123;&quot;reqtime&quot; =&gt; &quot;%&#123;[message][1]&#125;&quot;&#125;
            add_field =&gt; &#123;&quot;clientIP&quot; =&gt; &quot;%&#123;[message][2]&#125;&quot;&#125;
            add_field =&gt; &#123;&quot;squidCache&quot; =&gt; &quot;%&#123;[message][3]&#125;&quot;&#125;
            add_field =&gt; &#123;&quot;repsize&quot; =&gt; &quot;%&#123;[message][4]&#125;&quot;&#125;
            add_field =&gt; &#123;&quot;reqMethod&quot; =&gt; &quot;%&#123;[message][5]&#125;&quot;&#125;
            add_field =&gt; &#123;&quot;requestURL&quot; =&gt; &quot;%&#123;[message][6]&#125;&quot;&#125;
            add_field =&gt; &#123;&quot;username&quot; =&gt; &quot;%&#123;[message][7]&#125;&quot;&#125;
            add_field =&gt; &#123;&quot;requestOriginSite&quot; =&gt; &quot;%&#123;[message][8]&#125;&quot;&#125;
            add_field =&gt; &#123;&quot;mime&quot; =&gt; &quot;%&#123;[message][9]&#125;&quot;&#125;
            add_field =&gt; &#123;&quot;referer&quot; =&gt; &quot;%&#123;[message][10]&#125;&quot;&#125;
            add_field =&gt; &#123;&quot;agentCheck&quot; =&gt; &quot;%&#123;[message][11]&#125;&quot;&#125;
            add_field =&gt; &#123;&quot;dnsGroup&quot; =&gt; &quot;%&#123;[message][-1]&#125;&quot;&#125;
            remove_field =&gt; [&quot;offset&quot;, &quot;kafka&quot;, &quot;@version&quot;, &quot;file&quot;, &quot;message&quot;, &quot;messageClone&quot;]

       &#125;



       if [agentCheck] =~ &quot;ChinaCache&quot; &#123;

         grok &#123; match =&gt; &#123; &quot;agentCheck&quot; =&gt; &quot;OOPS&quot; &#125; &#125;

       &#125;



       mutate &#123;

          convert =&gt; &#123;

                &quot;timestamp&quot; =&gt; &quot;float&quot;       

            &quot;reqtime&quot; =&gt; &quot;integer&quot;

          &quot;repsize&quot; =&gt; &quot;integer&quot;

          &#125;

      remove_field =&gt; [&quot;agentCheck&quot;]

       &#125;





       ruby &#123;

       code =&gt; &quot;event[&#39;timestamp_str&#39;] = Time.at(event[&#39;timestamp&#39;]).strftime(&#39;%Y-%m-%dT%H:%M:%S.%LZ&#39;)&quot;

       &#125;



       date &#123; match =&gt; [ &quot;timestamp_str&quot;, &quot;ISO8601&quot; ] 

       &#125;



       mutate &#123;

             split =&gt; &#123; &quot;requestURL&quot; =&gt; &#39;/&#39; &#125;

      add_field =&gt; &#123;&quot;uriHost&quot; =&gt; &quot;%&#123;[requestURL][2]&#125;&quot;&#125;

      remove_field =&gt; [&quot;timestamp_str&quot;]

       &#125;



       mutate &#123;

             join =&gt; &#123; &quot;requestURL&quot; =&gt; &#39;/&#39; &#125;

       &#125;



       ruby &#123;

              code =&gt; &quot;event.cancel if 5 * 24 * 3600 &lt; (event[&#39;@timestamp&#39;]-::Time.now).abs&quot;

       &#125;





&#125;



output &#123;

if &quot;ChinaCache&quot; not in [agent] &#123;

#                   stdout &#123; codec =&gt; &quot;rubydebug&quot; &#125;

                   elasticsearch &#123;

                         index =&gt; &quot;logstash-%&#123;+YYYY.MM.dd.HH&#125;&quot;

                         workers =&gt; 1

                         flush_size =&gt; 5000

                         idle_flush_time =&gt; 1

                         hosts =&gt; [&quot;es-ip-1:9200&quot;,&quot;es-ip-2:9200&quot;,&quot;es-ip-3:9200&quot;,&quot;es-ip-4:9200&quot;,&quot;es-ip-5:9200&quot;,&quot;es-ip-6:9200&quot;,&quot;es-ip-7:9200&quot;]



                         &#125;

        &#125;

&#125;
</code></pre>
<h1 id="启动命令："><a href="#启动命令：" class="headerlink" title="启动命令："></a>启动命令：</h1><pre><code>nohup /home/ubuntu/logstash-2.2.2/bin/logstash -f /home/ubuntu/logstash-2.2.2/config/after-kafa-access.conf 2&gt;&amp;1 &gt; /home/ubuntu/logstash-2.2.2/logs/logstash-after-kafka-access.log &amp;
</code></pre>
<pre><code>nohup /home/ubuntu/logstash-2.2.2/bin/logstash -f /home/ubuntu/logstash-2.2.2/config/before-kafka-access.conf 2&gt;&amp;1 &gt; /home/ubuntu/logstash-2.2.2/logs/logstash-before-kafka.log &amp;
</code></pre>
<h1 id="logstash-6-1-1配置"><a href="#logstash-6-1-1配置" class="headerlink" title="logstash-6.1.1配置"></a>logstash-6.1.1配置</h1><p>##从filbeat到kafka的配置</p>
<pre><code>ubuntu@sp26:~/apps/logstash-6.1.1$ cat filebeat5055-kafkasp26-3.conf



input &#123;

    beats &#123;

        port =&gt; &quot;5055&quot;

type =&gt; &quot;log&quot;

    &#125;

&#125;

output &#123;

#   stdout &#123; codec =&gt; rubydebug &#125;

  kafka &#123;

    codec =&gt; &quot;json&quot;

    bootstrap_servers =&gt; &quot;37:9092,38:9092,39:9092,40:9092,41:9092&quot;

    topic_id =&gt; &quot;test&quot;

compression_type =&gt; &quot;snappy&quot;

value_serializer =&gt; &quot;org.apache.kafka.common.serialization.StringSerializer&quot;

  &#125;

&#125;
</code></pre>
<p>#检测</p>
<pre><code>/home/ubuntu/apps/logstash-6.1.1/bin/logstash -f /home/ubuntu/apps/logstash-6.1.1/filebeat5055-kafkasp26-3.conf  --config.test_and_exit
</code></pre>
<p>#启动</p>
<p><code>nohup /home/ubuntu/apps/logstash-6.1.1/bin/logstash -f /home/ubuntu/apps/logstash-6.1.1/filebeat5055-kafkasp26-3.conf --config.reload.automatic   2&gt;&amp;1 &gt;  /home/ubuntu/apps/logstash-6.1.1/logs/filebeat5055-kafkasp26-3.log  &amp;</code>　</p>

            
        </article>
    </div>
    
    <div class="nexmoe-post">
        <a href="/2018/12/18/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F-%E7%BC%93%E5%AD%98%E7%BB%84%E4%BB%B6kafka/">
            
                <div class="nexmoe-post-cover mdui-ripple" style="padding-bottom: 66.66666666666666%;"> 
                    <img data-src="https://cdn.jsdelivr.net/gh/nexmoe/nexmoe.github.io@latest/images/cover/5c3aec85a4343.jpg" data-sizes="auto" alt="大数据日志分析系统-缓存组件kafka" class="lazyload">
                    <h1>大数据日志分析系统-缓存组件kafka</h1>
                </div>
            
        </a>

        <div class="nexmoe-post-meta nexmoe-rainbow-fill">
            <a><i class="nexmoefont icon-calendar-fill"></i>2018年12月18日</a>
            <a><i class="nexmoefont icon-areachart"></i>770 字</a>
            <a><i class="nexmoefont icon-time-circle-fill"></i>大概 3 分钟</a>
        </div>

        <article>
            
                <h1 id="kafka简介"><a href="#kafka简介" class="headerlink" title="kafka简介"></a>kafka简介</h1><p>是一种高吞吐量的分布式发布订阅消息系统，当数据量不稳定，数据量大的时候想到它就对了。</p>
<h1 id="zookeeper简介"><a href="#zookeeper简介" class="headerlink" title="zookeeper简介"></a>zookeeper简介</h1><p>是一个分布式的，开放源码的分布式应用程序协调服务,很多地方用到, 最常见的是为集群提供基础的、高可用HA(High Availability)服务<br>是kafka集群的基础依赖，同时也是hadoop系列中实现HA的基础组件。<br>实现HDFS的NamaNode和YARN的ResourceManager的HA,Spark实现HA，<br>HBase主要用ZooKeeper来实现HMaster选举与主备切换、系统容错、RootRegion管理、Region状态管理和分布式SplitWAL任务管理等。</p>
<p>//===========================================================</p>
<p>两种集群的配置相差不大</p>
<h1 id="zookeeper集群配置："><a href="#zookeeper集群配置：" class="headerlink" title="zookeeper集群配置："></a>zookeeper集群配置：</h1><pre><code>ubuntu@sp1:~/kafka/config$ cat zookeeper.properties | grep -v &#39;#&#39;
dataDir=/mnt/data3/zk
clientPort=2181
tickTime=2000
initLimit=7
syncLimit=4
server.1=sp1:2888:3888
server.2=sp2:2888:3888
server.3=sp3:2888:3888
server.4=sp4:2888:3888
server.5=sp5:2888:3888
server.6=sp6:2888:3888
server.7=sp7:2888:3888
</code></pre>
<h2 id="强制杀死命令"><a href="#强制杀死命令" class="headerlink" title="强制杀死命令"></a>强制杀死命令</h2><p>ps aux |grep kafka |grep -v grep|cut -c 9-15 | xargs kill -9<br>ps aux |grep zookeeper |grep -v grep|cut -c 9-15 | xargs kill -9</p>
<h1 id="kafka-集群配置："><a href="#kafka-集群配置：" class="headerlink" title="kafka 集群配置："></a>kafka 集群配置：</h1><pre><code>ubuntu@sp1:~/kafka/config$ cat consumer.properties | grep -v &#39;#&#39;
zookeeper.connect=es1:2181,es2:2181,es3:2181,es4:2181,es5:2181
zookeeper.connection.timeout.ms=6000
group.id=test-consumer-group
</code></pre>
<pre><code>ubuntu@sp1:~/kafka/config$ cat server.properties | grep -v &#39;#&#39;
broker.id=1
port=9092
advertised.host.name=sp1
listeners=PLAINTEXT://sp1-host-ip:9092  
num.network.threads=10
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/mnt/data3/kafka-logs
num.partitions=20
num.recovery.threads.per.data.dir=5
log.retention.hours=8
log.retention.bytes=53687091200
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
log.cleaner.enable=false
zookeeper.connect=sp1:2181,sp2:2181,sp3:2181,sp4:2181,sp5:2181,sp6:2181,sp7:2181
zookeeper.connection.timeout.ms=6000
delete.topic.enable=true
auto.leader.rebalance.enable=true
num.replica.fetchers=5
</code></pre>
<h1 id="启动命令："><a href="#启动命令：" class="headerlink" title="启动命令："></a>启动命令：</h1><h2 id="1-zookeeper启动"><a href="#1-zookeeper启动" class="headerlink" title="1.zookeeper启动"></a>1.zookeeper启动</h2><p>sp1 - sp7在Ubuntu用户下 执行</p>
<pre><code>/home/ubuntu/zookeeper-3.4.7/bin/zkServer.sh start
</code></pre>
<h2 id="jps检查存在"><a href="#jps检查存在" class="headerlink" title="jps检查存在"></a>jps检查存在</h2><p>QuorumPeerMain</p>
<h2 id="状态查看"><a href="#状态查看" class="headerlink" title="状态查看"></a>状态查看</h2><pre><code>/home/ubuntu/zookeeper-3.4.7/bin/zkServer.sh status
</code></pre>
<p>查看为一主动多从启动正常</p>
<h2 id="文件查看"><a href="#文件查看" class="headerlink" title="文件查看"></a>文件查看</h2><pre><code>/home/ubuntu/zookeeper-3.4.7/bin/zkCli.sh -server localhost:2181
</code></pre>
<p>进入客户端 ls / 等命令查看</p>
<h1 id="2-kafka启动"><a href="#2-kafka启动" class="headerlink" title="2.kafka启动"></a>2.kafka启动</h1><h2 id="sp1到sp7执行"><a href="#sp1到sp7执行" class="headerlink" title="sp1到sp7执行"></a>sp1到sp7执行</h2><pre><code>nohup /home/ubuntu/kafka/bin/kafka-server-start.sh /home/ubuntu/kafka/config/server.properties 2&gt;&amp;1 &gt; /home/ubuntu/kafka/logs/kafka.log &amp;
</code></pre>
<p>当然也可以这样远程执行</p>
<pre><code>ssh sp1 nohup /home/ubuntu/kafka/bin/kafka-server-start.sh /home/ubuntu/kafka/config/server.properties 2&gt;&amp;1 &gt; /home/ubuntu/kafka/logs/kafka.log &amp;
</code></pre>
<h2 id="检查"><a href="#检查" class="headerlink" title="检查"></a>检查</h2><p>~/kafka/bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker –broker-info –group kafka_es –topic kafka_es –zookeeper localhost:2181</p>
<p>就可以看机器是否正常了</p>
<h1 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h1><p>很可能出现kafka个别分片堆积问题：例如现在kafka有35个分片，只有2个分片产生堆积，通过命令</p>
<pre><code>~/kafka/bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --broker-info --group kafka_es --topic kafka_es --zookeeper localhost:2181
</code></pre>
<p>查看，我遇见过是消费线程小于分片数量（现象是用命令查看是不同的分片Pid 拥有相同的 Owner），这个时候增加消费者进程即可（我个人认为数据量大时消费者要多于分片数量  这样不容易出现挂掉一两个消费者出现分片被堆积的情况）
　</p>

            
        </article>
    </div>
    
    <div class="nexmoe-post">
        <a href="/2018/12/18/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F-%E8%BE%B9%E7%BC%98%E8%8A%82%E7%82%B9%E6%97%A5%E5%BF%97%E4%B8%8A%E4%BC%A0-flume%EF%BC%8Cfilbeat-logstash-forward/">
            
                <div class="nexmoe-post-cover mdui-ripple" style="padding-bottom: 66.66666666666666%;"> 
                    <img data-src="https://cdn.jsdelivr.net/gh/nexmoe/nexmoe.github.io@latest/images/cover/5c3aec85a4343.jpg" data-sizes="auto" alt="大数据日志分析系统边缘节点日志上传-flume，filbeat,logstash-forward" class="lazyload">
                    <h1>大数据日志分析系统边缘节点日志上传-flume，filbeat,logstash-forward</h1>
                </div>
            
        </a>

        <div class="nexmoe-post-meta nexmoe-rainbow-fill">
            <a><i class="nexmoefont icon-calendar-fill"></i>2018年12月18日</a>
            <a><i class="nexmoefont icon-areachart"></i>301 字</a>
            <a><i class="nexmoefont icon-time-circle-fill"></i>大概 1 分钟</a>
        </div>

        <article>
            
                <h1 id="上传组件简介："><a href="#上传组件简介：" class="headerlink" title="上传组件简介："></a>上传组件简介：</h1><p>它们都是很好的资源上传工具，直接指定目录、文件就可以上传，通用功能不多说，区别除了与本公司产品兼容性好以外：</p>
<ul>
<li>filebeat elastic(ELK)官网推荐：占用资源少</li>
<li>flume    apache官网产品：可定制性强</li>
<li>logstash-forward  已经过期的产品不多说。</li>
</ul>
<p>因为需求简单，只是边缘节点日志上传最终选用了filebeat </p>
<p> #正确格式原始日志示例：</p>
<pre><code>1512231002.276     89 117.169.22.89 TCP_REFRESH_HIT/304 199 GET http://www.baidu.com/download/EF_patch_1.0.3.2-1.0.3.3.exe  - DIRECT/122.228.246.78 - &quot;-&quot; &quot;Mozilla/5.0 Gecko/20100115 Firefox/3.6&quot; &quot;-&quot;
</code></pre>
<p> #测试时追加日志的shell</p>
<pre><code>echo &#39;1512231002.276     89 117.169.22.89 TCP_REFRESH_HIT/304 199 GET http://www.baidu.com/download/EF_patch_1.0.3.2-1.0.3.3.exe  - DIRECT/122.228.246.78 - &quot;-&quot; &quot;Mozilla/5.0 Gecko/20100115 Firefox/3.6&quot; &quot;-&quot;&#39;  &gt;&gt;  /data/cache1/filbeat_conf/logsdir/test.log
</code></pre>
<p> #filbeat配置示例：</p>
<pre><code>[root@filbeathost filbeat_conf]# cat /data/cache1/filbeat_conf/filebeat-file-sp265055.yml
filebeat.prospectors:
- type: log
 paths:
   - /data/cache1/filbeat_conf/logsdir/* 
output.logstash:
 hosts: [&quot;logstash-host1:5055&quot;,&quot;logstash-host2:5055&quot;,&quot;logstash-host3:5055&quot;,&quot;logstash-host4:5055&quot;,&quot;logstash-host5:5055&quot;]
</code></pre>
<p>#启动</p>
<pre><code>nohup filebeat -e -c /data/cache1/filbeat_conf/filebeat-file-sp265055.yml  -d &quot;publish&quot; &amp;
</code></pre>

            
        </article>
    </div>
    
    <div class="nexmoe-post">
        <a href="/2018/12/18/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/">
            
                <div class="nexmoe-post-cover mdui-ripple" style="padding-bottom: 66.66666666666666%;"> 
                    <img data-src="https://cdn.jsdelivr.net/gh/nexmoe/nexmoe.github.io@latest/images/cover/5c3aec85a4343.jpg" data-sizes="auto" alt="大数据日志分析系统" class="lazyload">
                    <h1>大数据日志分析系统</h1>
                </div>
            
        </a>

        <div class="nexmoe-post-meta nexmoe-rainbow-fill">
            <a><i class="nexmoefont icon-calendar-fill"></i>2018年12月18日</a>
            <a><i class="nexmoefont icon-areachart"></i>1.9k 字</a>
            <a><i class="nexmoefont icon-time-circle-fill"></i>大概 8 分钟</a>
        </div>

        <article>
            
                <h1 id="原始日志量"><a href="#原始日志量" class="headerlink" title="原始日志量"></a>原始日志量</h1><p>每小时高的是否达到了 45303452条日志（四千五百多万条原始日志） ，某天日志量（这个随便选的）422110779 条（4亿两千多万）</p>
<h1 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h1><ul>
<li>1）对原始日志按域名进行分析包括： 请求数分析、独立IP分析、PV分析、地区分布运营商分布分析（根据ip计算）、浏览器操作系统分布分析（根据原始日志的agent进行分析）、热点页面分析、文件类型分析</li>
<li>2）原始日志按域名、按天、按小时进行打包。</li>
</ul>
<h1 id="两种方案"><a href="#两种方案" class="headerlink" title="两种方案"></a>两种方案</h1><h1 id="方案１"><a href="#方案１" class="headerlink" title="方案１"></a>方案１</h1><ul>
<li>→logstash-forward(边缘设备)  </li>
<li>→ logstash (用logstast-before配置文件) </li>
<li>→ Kafka (同时依赖zookeeper) </li>
<li>→ logstash (用logstash-after配置文件) </li>
<li>→ elaticsearch  </li>
<li>→ python脚本 </li>
<li>→ 统计日志本地然后上传到hadoop,各种统计结果到elasticsearch（nginx负载均衡）   </li>
<li>→  界面展示</li>
</ul>
<p>边缘节点服务器会产生很多用户请求日志，要对日志进行各种分析和原始日志打包，最终分析结果进行收费、让客户可以获取请求日志各种分析结果、为客户进行原始日志按域名按天按小时分割打包。</p>
<h1 id="方案２"><a href="#方案２" class="headerlink" title="方案２"></a>方案２</h1><ul>
<li>–&gt; filebeat(或flume) </li>
<li>–&gt; logstash </li>
<li>–&gt; kafka(kafka依赖zookeeper) </li>
<li>–&gt; spark统计计算 </li>
<li>–&gt; 统计各种结果到elasticsearch（nginx负载均衡） </li>
<li>–&gt; 界面展示</li>
</ul>
<p>–&gt; flume(自定义sink插件、验证可行待完成)<br>–&gt; 原始日志本地打包<br>–&gt; 原始日志hadoop上传 (当然这里也可以用hbase进行日志存储)</p>
<h1 id="大数据实时计算需要的几个基本组件（一定要注意版本问题，java大数据机器间通信用的是RPC-而不是restful-api-如果版本不对应很可能出现版本间的兼容问题）："><a href="#大数据实时计算需要的几个基本组件（一定要注意版本问题，java大数据机器间通信用的是RPC-而不是restful-api-如果版本不对应很可能出现版本间的兼容问题）：" class="headerlink" title="大数据实时计算需要的几个基本组件（一定要注意版本问题，java大数据机器间通信用的是RPC 而不是restful_api,如果版本不对应很可能出现版本间的兼容问题）："></a>大数据实时计算需要的几个基本组件（一定要注意版本问题，java大数据机器间通信用的是RPC 而不是restful_api,如果版本不对应很可能出现版本间的兼容问题）：</h1><ul>
<li><p>1.日志收集    -从CDN边缘节点服务器进行日志收集</p>
</li>
<li><p>2.日志缓存    -收集上来的日志存储到一个缓存设备</p>
</li>
<li><p>3.数据计算    -对收集的日志进行计算，域名请求数分析、地区统计等等</p>
</li>
<li><p>4.计算结果存储    -对各种分析结果进行存储，要方便查找</p>
</li>
<li><p>5.日志打包结果存储</p>
<h2 id="公司刚开始的日志系统分布："><a href="#公司刚开始的日志系统分布：" class="headerlink" title="公司刚开始的日志系统分布："></a>公司刚开始的日志系统分布：</h2></li>
<li><p>logstash-forward (边缘节点日志收集，上传到有logstash的机器)       -》</p>
</li>
<li><p>kafka  强大的数据缓存组建          （由logstash收集日志到kafka）    -》</p>
</li>
<li><p>elasticsearch (分布式、可扩展、实时的搜索与数据分析引擎)  (用logstash从kafka取出数据存到es)  -&gt;</p>
</li>
<li><p>spark（大规模数据计算引擎，从es取出原始日志然后通过spark计算结果）    -》</p>
</li>
<li><p>elasticsearch （进行计算结果数据存储），hadoop（原始日志打包存储） -》</p>
</li>
<li><p>nginx  + django服务  进行反向代理、负载均衡、地址隐藏            django进行界面展示-》</p>
</li>
<li><p>可客户直接访问观看</p>
<h2 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h2><p>zookeeper 3.4.7<br>kafka_2.11-0.8.2.1<br>logstash-2.2.2<br>elasticsearch-2.4.6<br>hadoop-2.6.4<br>spark-1.6.1 </p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>现在这样的系统由于经常出现问题，es报红，或者计算有问题等，这是由于刚开始一个人做完还没完全稳定就直接撤人了，转了几次到了我手里（因为我懂java，android但是部门基本上是以python为主）。到我手里了是个挑战也是一个机遇嘛，然后就开始了填坑之旅。。。。。。。。。。。。<br>还有一点是这样不能够很好的保持数据的实时性。　</p>
<h2 id="改进："><a href="#改进：" class="headerlink" title="改进："></a>改进：</h2><p>其中遇到也解决了各种问题，就举例最主要的两个。<br>    1.线上的客户投诉获取不到原始日志，没那么多时间弄懂了再改进所以解决是 –》 写python脚本（到了这家公司开始用与部门统一的python）—》功能是从elasticsearch获取到某个域名原始日志然后写入本地文件（虽然不会写，但是这么多年编程scala的大概对日志的处理逻辑还是能看懂的），本地压缩，然后python调用hadoop本地命令行将日志上传到hadoop，先临时解决了问题<br>    2.elasticsearch报红、kafka堆积<br>    不知道怎样解决，只能看日志了，尝试用elasticsearch升级到了5.5.2，发现不会出现这样的问题。  但是又出现了新的问题：spark不能兼容这样的es版本，  给老大反映情况（提了 我倾向的用python脚本计算这一条路和对es降级尝试的路），听命于领导就先对原来的elasticsearch-2.4.6进行了配置改动-但是发现还是偶尔会出现es报红的情况。    只能用另一条路用python脚本代替spark，使用es自身的聚合功能进行计算，这样就解决了问题。<br>    总结：所以最后的解决办法是 去掉spark        先用python脚本直接聚合统计方式请求es获取结果,这样也满足线上要求，就先这样了。</p>
<h1 id="结果："><a href="#结果：" class="headerlink" title="结果："></a>结果：</h1></li>
<li><p>logstash-forward (边缘节点日志收集，上传到有logstash的机器)       -》</p>
</li>
<li><p>kafka  强大的数据缓存组建          （由logstash收集日志到kafka）    -》</p>
</li>
<li><p>elasticsearch (分布式、可扩展、实时的搜索与数据分析引擎)  (用logstash从kafka取出数据存到es)  -&gt;</p>
</li>
<li><p>python脚本（调用elasticsearch的resultful_api获取统计结果，同时打包原始日志到本地上传到hadoop）    -》</p>
</li>
<li><p>elasticsearch （进行计算结果数据存储），hadoop（原始日志打包存储） -》</p>
</li>
<li><p>nginx  + django服务  进行反向代理、负载均衡、地址隐藏            django进行界面展示-》</p>
</li>
<li><p>客户直接访问观看</p>
<h2 id="版本-1"><a href="#版本-1" class="headerlink" title="版本"></a>版本</h2><p>zookeeper 3.4.7       <br>kafka_2.11-0.8.2.1   <br>logstash-2.2.2    <br>elasticsearch-5.5.2      <br>hadoop-2.6.4   <br>python以及python elasticsearch库 </p>
<h2 id="现在的架构："><a href="#现在的架构：" class="headerlink" title="现在的架构："></a>现在的架构：</h2><p>公司在我刚开始接手的同时已经公司招聘了一个大数据人员（但不是本部门的），本部门也要有新项目有更大的数据量要计算需要跟他对接，但是等了好几个月仍然没有啥成果，老大忍不住了让我去看看他的大数据代码、提改进建议催进度（他主要用spark最终结果存到hbase，java写的代码），然后发现代码写的比较烂（因为java基本的静态变量 方法封装 继承多态等一看就是新手），业务逻辑也有点问题-跟老大反映，但是不同部门管不着也不能说啊，细节不说了，最终又开始了新架构的尝试之旅。</p>
</li>
<li><p>1.filbeat 边缘节点日志收集，上传到有logstash的机器（或者可以用flume)    -》</p>
</li>
<li><p>2.kafka  强大的数据缓存组件         （由logstash收集日志到kafka）    -》</p>
</li>
<li><p>3.spark（大规模数据计算引擎，从kafka取出日志，通过scala编写的spark代码把计算结果存入es）    -》</p>
</li>
<li><p>4.elasticsearch （进行计算结果数据存储） -》 </p>
</li>
<li><p>5.nginx + django   界面展示或接口让客户获取服务</p>
</li>
</ul>
<p> 同时并行的原始日志打包   （刚开始日志打包考虑到了用spark或者flume直接上传到hadoop，但是后来发现现有机器这样的速度赶不上实际需要，）</p>
<ul>
<li>3.flume(自定义sink插件，filter插件 从kafka的另一个topic中获取日志数据，把日志按域名，按小时打包到本地）     -》</li>
<li>4.python 调用hadoop命令行上传本地打包好的日志到hadoop -&gt;</li>
<li>5.nginx + django   界面展示或接口让客户获取服务</li>
</ul>
<h2 id="版本信息"><a href="#版本信息" class="headerlink" title="版本信息"></a>版本信息</h2><p>apache-flume-1.6.0-bin  hadoop-2.6.4   kafka_2.11-1.0.0  spark-1.6.1-bin-hadoop2.6<br>elasticsearch-5.5.2     hbase         jdk1.8.0_144  logstash-6.1.1    zookeeper-3.4.5<br>jdk1.7.0_45(刚开始hadoop使用 后来spark要求更高就用了1.8版本） </p>
<h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><p>当然每个阶段都需要增加监控，这里用的是zabbix监控配合脚本监控</p>

            
        </article>
    </div>
    
</section>

        <!--<div class="nexmoe-post-right">
          <div class="nexmoe-fixed">
            <div class="nexmoe-tool">
              <a href="#nexmoe-content" class="toc-link" aria-label="回到顶部" title="top"><button class="mdui-fab mdui-ripple"><i class="nexmoefont icon-caret-top"></i></button></a>
            </div>
          </div>
        </div>-->
    </div>
  </div>
  <script src="https://cdn.jsdelivr.net/combine/npm/lazysizes@5.1.0/lazysizes.min.js,gh/highlightjs/cdn-release@9.15.8/build/highlight.min.js,npm/mdui@0.4.3/dist/js/mdui.min.js?v=1"></script>
<script>
	hljs.initHighlightingOnLoad();
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>


<script src="https://cdn.jsdelivr.net/gh/xtaodada/xtaodada.github.io@0.0.2/copy.js"></script>
 

<script src="/js/app.js?v=1619942251119"></script>

<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js"></script>
<script>
	$(".justified-gallery").justifiedGallery({
		rowHeight: 160,
		margins: 10,
	});
</script>

  





</body>

</html>
